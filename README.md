<h1 align="center">Single-channel source separation with convolutional neural networks</h1>

<div align="justify">
  <p>This project is framed within the course of Computational Intelligence, offered at FICH-UNL for the program of Ingeniería en Informática, serving as its final project.</p>
  <p>The <b>motivation</b> behind this project is to be able to separate different sources within an audio, whether for recreational purposes such as isolating instruments in a song to facilitate learning their notes individually, or for practical applications such as clearly separating voices to enhance the performance of cochlear implants for individuals with hearing impairment.</p>
  <p>We approached this project utilizing <b>convolutional neural networks</b> after researching and studying various sources and projects that pursued similar objectives, as they appear to be the most efficient option among other methods. Additionally, we seized the opportunity to gain experience and enhance our understanding of this type of neural networks, as they were not part of the curriculum at the time of taking the course.</p>
  <p>The database used for the inputs was MUSDB18 and the starting point for the project was the article 'Monoaural Audio Separation Using Deep Convolutional Neural Networks' by Chandna et al. The final code manages to separate the sources in audios with two sources, for easier convergence and implementation due to the limited time given to work on the project to reach the deadline. It could be improved in future projects.</p>
  <p>We have made the source code available, along with various results and their corresponding audio outputs, convergence information, charts, and the final experiment report.</p>
</div>
